--- src/BigBWA.java
+++ src/BigBWA.java
@@ -1,6 +1,14 @@
 /**
- * Copyright 2015 José Manuel Abuín Mosquera <josemanuel.abuin@usc.es>
+ * Copyright 2016 Eun-kyu Byun <ekbyun@kisti.re.kr>
  * 
+ * This file is modified version of BigBWA.hava file which is a part of BigBWA
+ * Byun modified the file to be executed on luster file system envoronemnt 
+ * through lusterfs-hadoop adpafor.
+ *
+ * The following sentences are introduction of original BigBWA.java file.
+ *
+ * Copyright 2015 José Manuel Abuín Mosquera <josemanuel.abuin@usc.e.es> 
+ *
  * This file is part of BigBWA.
  *
  * BigBWA is free software: you can redistribute it and/or modify
@@ -150,41 +158,43 @@
 		conf.set("outputGenomics",outputPath);
 		
 		//==================Partition number==================
-		if(options.getPartitionNumber() != 0) {
-			try {
-				FileSystem fs = FileSystem.get(conf);
-				
-				Path inputFilePath = new Path(inputPath);
-				
-				ContentSummary cSummary = fs.getContentSummary(inputFilePath);
-
+		FileSystem fs = null;
+		Path inputFilePath = null;
+		try {
+			fs = FileSystem.get(conf);
+		
+			inputFilePath = new Path(inputPath);
 
+			if(options.getPartitionNumber() != 0) {
+				ContentSummary cSummary = fs.getContentSummary(inputFilePath);
 				long length = cSummary.getLength();
-
-
-				fs.close();
-				
 				conf.set("mapreduce.input.fileinputformat.split.maxsize", String.valueOf((length)/options.getPartitionNumber()));
 				conf.set("mapreduce.input.fileinputformat.split.minsize", String.valueOf((length)/options.getPartitionNumber()));
 			}
-			catch (IOException e) {
-				// TODO Auto-generated catch block
-				e.printStackTrace();
-				LOG.error(e.toString());
+		}
+		catch (IOException e) {
+			// TODO Auto-generated catch block
+			e.printStackTrace();
+			LOG.error(e.toString());
 
-				System.exit(1);
-			}
-			
+			System.exit(1);
 		}
 		
+		//-----------------------MODIFIED----------------------
+		BufferedReader d = new BufferedReader(new InputStreamReader(fs.open(inputFilePath)));
+		String delim = d.readLine().substring(0,8);
+
+		d.close();
+		fs.close();
+
+		conf.set("textinputformat.record.delimiter","\n" + delim);
+		conf.set("headerBytes", delim.toString());
 		
-		//Job job = new Job(conf,"BigBWA_"+outputPath);
 		Job job = Job.getInstance(conf,"BigBWA_"+outputPath);
 		
 		
 		job.setJarByClass(BigBWA.class);
 		job.setMapperClass(BigBWAMap.class);
-		//job.setCombinerClass(BigBWACombiner.class);
 
 		if(useReducer){
 			job.setReducerClass(BigBWAReducer.class);
@@ -214,23 +224,24 @@
 	//Mapper class. We follow the In-Mapper Combining pattern
 	public static class BigBWAMap extends Mapper<Object,Text,IntWritable,Text> {
 
-		File fout;
-		FileOutputStream fos;
-		BufferedWriter bw;
 		int identificador;
 		
-		String tmpFileString = "";
 		int jobID;
 
+		String tmpFileString = "";
+		File fout;
+		FileOutputStream fos;
+		BufferedWriter bw;
+		boolean f1exist;
+
 		String tmpFileString2 = "";
 		File fout2;
+		FileOutputStream fos2;
 		
 		//SAI files
+		
 		String saiFile1 = "";
 		String saiFile2 = "";
-		
-		FileOutputStream fos2;
-		BufferedWriter bw2;
 
 		String[] initValues;
 		String[] values1;
@@ -240,9 +251,11 @@
 		String indexRoute;
 
 		String rgheader = "";
-		
+
 		String outputFileName = "";
-		
+
+		String header;		
+
 		//In the setup, we create each split local file
 		@Override
 		protected void setup(Context context) {
@@ -252,40 +265,38 @@
 
 			Configuration conf = context.getConfiguration();
 
-			tmpDir = conf.get("hadoop.tmp.dir","/tmp/");
-			
-			if(tmpDir == null || tmpDir.isEmpty()) {
-				tmpDir = "/tmp/";
-			}
-			
 			indexRoute = conf.get("indexRoute");
 
-			tmpFileString = tmpDir+"/HadoopTMPFile-"+identificador+"-"+String.valueOf(jobID);
+			header = conf.get("headerBytes");
 
-			fout = new File(tmpFileString);
-			try {
-				fos = new FileOutputStream(fout);
-			} catch (FileNotFoundException e) {
-				
-				LOG.error(e.toString());
-				e.printStackTrace();
-			}
+			tmpDir = conf.get("fs.lustrefs.shared_tmp.dir");
 
-			bw = new BufferedWriter(new OutputStreamWriter(fos));
+			tmpFileString = tmpDir+"/BigBWA_input_temp-"+identificador;
 
+			fout = new File(tmpFileString);
+			f1exist = fout.exists();
+			if( !f1exist ) {
+				try {
+					fos = new FileOutputStream(fout);
+				} catch (FileNotFoundException e) {
+					// TODO Auto-generated catch block
+					e.printStackTrace();
+				}
 
-			if((conf.get("paired").equals("true"))){
-				tmpFileString2 = tmpDir+"/HadoopTMPFile-"+identificador+"_2"+"-"+String.valueOf(jobID);
+				bw = new BufferedWriter(new OutputStreamWriter(fos));
+			} else if(conf.get("paired").equals("true")){
+				tmpFileString2 = tmpDir+"/BigBWA_input_temp-"+identificador+"_2";
 				fout2 = new File(tmpFileString2);
 
 				try {
 					fos2 = new FileOutputStream(fout2);
 				} catch (FileNotFoundException e) {
 					// TODO Auto-generated catch block
+					LOG.error(e.toString());
 					e.printStackTrace();
 				}
 
-				bw2 = new BufferedWriter(new OutputStreamWriter(fos2));
+				bw = new BufferedWriter(new OutputStreamWriter(fos2));
 			}
 
 		} 
@@ -294,43 +305,11 @@
 		@Override
 		public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
 			try{
-
 				Configuration conf = context.getConfiguration();
 
-				if((conf.get("paired").equals("true"))){
-
-					initValues = value.toString().split("<part>");
-
-					values1 = initValues[0].toString().split("<sep>");
-					values2 = initValues[1].toString().split("<sep>");
-
-					for(String newValue: values1){
-						bw.write(newValue);
-						bw.newLine();
-					}
-
-					for(String newValue: values2){
-						bw2.write(newValue);
-						bw2.newLine();
-					}
-
-					values1=null;
-					values2=null;
-					initValues=null;
-
-				}
-				else{
-					values1 = value.toString().split("<sep>");
-
-					for(String newValue: values1){
-						bw.write(newValue);
-						bw.newLine();
-
-					}
-					values1=null;
-				}
-
-
+				bw.write(header);
+				bw.write(value.toString());
+				bw.newLine();
 			}
 			catch(Exception e){
 				System.out.println(e.toString());
@@ -342,36 +321,32 @@
 		public void cleanup(Context context) throws InterruptedException{
 
 			try {
+				bw.close();
 
-				Configuration conf = context.getConfiguration();
-				String[] args;
-				
+				if( !f1exist ) return;
 
-				bw.close();
+				Configuration conf = context.getConfiguration();
 
-				
 				if(conf.get("rgheader")!=null && !conf.get("rgheader").equals("")){
 					this.rgheader = conf.get("rgheader");
 				}
-				
-				String outputDir = context.getConfiguration().get("outputGenomics");
+
+				String[] args;
+
+				String outputDir = conf.get("outputGenomics");
+				tmpDir = conf.get("fs.lustrefs.mount")+"/user/"+System.getProperty("user.name") +"/" + outputDir;
 				
 				//Paired algorithms
 				if((conf.get("paired").equals("true"))){
-					bw2.close();
-
-					
 
 					if(conf.get("bwathreads")!=null && !conf.get("bwathreads").equals("")){
-						
 						if(this.rgheader != ""){
-							
 							args = new String[11];
-							
+
 							args[0] = "bwa";
 							args[1] = "mem";
 							args[2] = "-f";
-							args[3] = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sam";
+							args[3] = tmpDir+"/Output"+this.identificador+".sam";
 							args[4] = "-t";
 							args[5] = conf.get("bwathreads");
 							args[6] = "-R";
@@ -379,60 +354,58 @@
 							args[8] = indexRoute;
 							args[9] = tmpFileString;
 							args[10] = tmpFileString2;
-						}
-						
-						else{
+
+							outputFileName = args[3];
+						} 
+						else {
 							args = new String[9];
 
 							args[0] = "bwa";
 							args[1] = "mem";
 							args[2] = "-f";
-							args[3] = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sam";
+							args[3] = tmpDir+"/Output"+this.identificador+".sam";
 							args[4] = "-t";
 							args[5] = conf.get("bwathreads");
 							args[6] = indexRoute;
 							args[7] = tmpFileString;
 							args[8] = tmpFileString2;
+
+							outputFileName = args[3];
 						}
-						
-						outputFileName = args[3];
+
 
 						//bwa execution
 						BwaJni.Bwa_Jni(args);
 					}
 					else if((conf.get("mem")!=null)&&(conf.get("mem").equals("true"))){
-						
 						if(this.rgheader != ""){
 							args = new String[9];
 
 							args[0] = "bwa";
 							args[1] = "mem";
 							args[2] = "-f";
-							args[3] = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sam";
+							args[3] = tmpDir+"/Output"+this.identificador+".sam";
 							args[4] = "-R";
 							args[5] = this.rgheader;
 							args[6] = indexRoute;
 							args[7] = tmpFileString;
 							args[8] = tmpFileString2;
-							
+	
 							outputFileName = args[3];
 						}
-						
-						else{
-							args = new String[7];
+						else {
+							args = new String[9];
 
 							args[0] = "bwa";
 							args[1] = "mem";
 							args[2] = "-f";
-							args[3] = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sam";
+							args[3] = tmpDir+"/Output"+this.identificador+".sam";
 							args[4] = indexRoute;
 							args[5] = tmpFileString;
 							args[6] = tmpFileString2;
-
+	
 							outputFileName = args[3];
 						}
-						
-						
 
 						//bwa execution
 						BwaJni.Bwa_Jni(args);
@@ -443,7 +416,7 @@
 						args[0] = "bwa";
 						args[1] = "bwasw";
 						args[2] = "-f";
-						args[3] = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sam";
+						args[3] = tmpDir+"/Output"+this.identificador+".sam";
 						args[4] = indexRoute;
 						args[5] = tmpFileString;
 						args[6] = tmpFileString2;
@@ -456,8 +429,8 @@
 					else if((conf.get("aln")!=null)&&(conf.get("aln").equals("true"))){
 						args = new String[6];
 
-						this.saiFile1 = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sai";
-						this.saiFile2 = tmpDir+"/Output"+this.identificador+"-2-"+String.valueOf(jobID)+".sai";
+						this.saiFile1 = tmpDir+"/Output"+this.identificador+".sai";
+						this.saiFile2 = tmpDir+"/Output"+this.identificador+"-2.sai";
 
 						args[0] = "bwa";
 						args[1] = "aln";
@@ -487,35 +460,32 @@
 						//bwa execution for aln2
 						BwaJni.Bwa_Jni(args2);
 
-						//Sampe
-						if(this.rgheader!=""){
+						if(this.rgheader!="") {
 							args = new String[11];
 							args[0] = "bwa";
 							args[1] = "sampe";
 							args[2] = "-f";
-							args[3] = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sam";
+							args[3] = tmpDir+"/Output"+this.identificador+".sam";
 							args[4] = indexRoute;
-							args[5] = "-r";
-							args[6] = this.rgheader;
+                                                        args[5] = "-R";
+                                                        args[6] = this.rgheader;
 							args[7] = saiFile1;
 							args[8] = saiFile2;
 							args[9] = tmpFileString;
 							args[10] = tmpFileString2;
 						}
-						else{
+						else {
 							args = new String[9];
 							args[0] = "bwa";
 							args[1] = "sampe";
 							args[2] = "-f";
-							args[3] = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sam";
+							args[3] = tmpDir+"/Output"+this.identificador+".sam";
 							args[4] = indexRoute;
 							args[5] = saiFile1;
 							args[6] = saiFile2;
 							args[7] = tmpFileString;
 							args[8] = tmpFileString2;
 						}
-						
-						
 
 						outputFileName = args[3];
 						
@@ -535,21 +505,13 @@
 
 					}
 
-					//We copy the results to HDFS and delete tmp files from local filesystem
-					FileSystem fs = FileSystem.get(context.getConfiguration());
-
-					fs.copyFromLocalFile(new Path(outputFileName), new Path(outputDir+"/Output"+this.identificador+".sam"));
-					fs.copyFromLocalFile(new Path(tmpFileString), new Path(outputDir+"/Input"+this.identificador+"_1.fq"));
-					fs.copyFromLocalFile(new Path(tmpFileString2), new Path(outputDir+"/Input"+this.identificador+"_2.fq"));
-
-					File outputFile = new File(outputFileName);
-					outputFile.delete();
-
-					fout.delete();
-					fout2.delete();
+					if( f1exist ) {
+						fout.delete();
+						fout2.delete();
+					}
 
 					if((conf.get("useReducer")!=null)&&(conf.get("useReducer").equals("true"))){
-						context.write(new IntWritable(this.identificador), new Text(outputDir+"/Output"+this.identificador+".sam"));
+						context.write(new IntWritable(this.identificador), new Text(outputDir+"/Output-"+this.identificador+".sam"));
 					}
 
 
@@ -563,21 +525,13 @@
 						args[0] = "bwa";
 						args[1] = "mem";
 						args[2] = "-f";
-						args[3] = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sam";
+						args[3] = tmpDir+"/Output"+this.identificador+".sam";
 						args[4] = indexRoute;
 						args[5] = tmpFileString;
 
 						//bwa execution
 						BwaJni.Bwa_Jni(args);
 
-						//We copy the results to HDFS and delete tmp files from local filesystem
-						FileSystem fs = FileSystem.get(context.getConfiguration());
-
-						fs.copyFromLocalFile(new Path(args[3]), new Path(outputDir+"/Output"+this.identificador+".sam"));
-						fs.copyFromLocalFile(new Path(tmpFileString), new Path(outputDir+"/Input"+this.identificador+".fq"));
-
-						File outputFile = new File(args[3]);
-						outputFile.delete();
 						fout.delete();
 
 					}
@@ -588,7 +542,7 @@
 						args[0] = "bwa";
 						args[1] = "bwasw";
 						args[2] = "-f";
-						args[3] = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sam";
+						args[3] = tmpDir+"/Output"+this.identificador+".sam";
 						args[4] = indexRoute;
 						args[5] = tmpFileString;
 
@@ -597,21 +551,13 @@
 						//bwa execution
 						BwaJni.Bwa_Jni(args);
 
-						//We copy the results to HDFS and delete tmp files from local filesystem
-						FileSystem fs = FileSystem.get(context.getConfiguration());
-
-						fs.copyFromLocalFile(new Path(args[3]), new Path(outputDir+"/Output"+this.identificador+".sam"));
-						fs.copyFromLocalFile(new Path(tmpFileString), new Path(outputDir+"/Input"+this.identificador+".fq"));
-
-						File outputFile = new File(args[3]);
-						outputFile.delete();
 						fout.delete();
 
 					}
 					else if(conf.get("aln").equals("true")){
 						args = new String[6];
 						
-						String saiFile = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sai";
+						String saiFile = tmpDir+"/Output"+this.identificador+".sai";
 
 						args[0] = "bwa";
 						args[1] = "aln";
@@ -627,7 +573,7 @@
 						args[0] = "bwa";
 						args[1] = "samse";
 						args[2] = "-f";
-						args[3] = tmpDir+"/Output"+this.identificador+"-"+String.valueOf(jobID)+".sam";
+						args[3] = tmpDir+"/Output"+this.identificador+".sam";
 						args[4] = indexRoute;
 						args[5] = saiFile;
 						args[6] = tmpFileString;
@@ -640,28 +586,14 @@
 						File tempFile = new File(saiFile);
 						tempFile.delete();
 
-						
-						
-						//We copy the results to HDFS and delete tmp files from local filesystem
-						//String outputDir = context.getConfiguration().get("outputGenomics");
-
-						FileSystem fs = FileSystem.get(context.getConfiguration());
-
-						fs.copyFromLocalFile(new Path(args[3]), new Path(outputDir+"/Output"+this.identificador+".sai"));
-						fs.copyFromLocalFile(new Path(tmpFileString), new Path(outputDir+"/Input"+this.identificador+".fq"));
-
-						File outputFile = new File(args[3]);
-
 						fout.delete();
-						outputFile.delete();
 					}
 					
 					if((conf.get("useReducer")!=null)&&(conf.get("useReducer").equals("true"))){
-						context.write(new IntWritable(this.identificador), new Text(outputDir+"/Output"+this.identificador+".sam"));
+						context.write(new IntWritable(this.identificador), new Text(outputFileName));
 					}
 
 				}
-
 			} catch (Exception e) {
 				// TODO Auto-generated catch block
 				e.printStackTrace();
@@ -670,7 +602,7 @@
 				
 				//FASTQ splits
 				this.fout.delete();
-				this.fout2.delete();
+				if( this.fout != null ) this.fout2.delete();
 				
 				//SAI outputs
 				if(!this.saiFile1.isEmpty()){
@@ -707,9 +639,6 @@
 		@Override
 		protected void setup(Context context) {
 
-			//this.outputDir = context.getConfiguration().get("outputGenomics");
-			//this.outputFile = this.outputDir+"/FinalOutput.sam";
-
 			this.inputFiles = new HashMap<Integer,String>();
 
 		}
@@ -717,7 +646,6 @@
 		@Override
 		public void reduce(IntWritable key, Iterable<Text> values, Context context) throws IOException, InterruptedException {
 			try{
-
 				//In theory, there is just one value per key
 				for (Text val : values) {
 					inputFiles.put(key.get(), val.toString());
@@ -749,7 +677,6 @@
 				while ((line = d.readLine())!=null) {
 
 					if((line.startsWith("@") && readHeader) || (!line.startsWith("@")) ){
-						//bufferOut.write(line);
 						context.write(NullWritable.get(), new Text(line));
 					}
 
@@ -764,8 +691,6 @@
 
 			}
 
-			//bufferOut.close();
-
 		}
 
 	}
